import fs from 'fs'
import path from 'path'
import { ReplyInput } from './types'
import { selectSections } from './knowledge'
import { logger } from './logger'
import YAML from 'yaml'
import { getUserBotConfig, getUserKnowledgeForAI } from './userProfiles'

// Fallback: load global config if user config not available
function loadGlobalBotConfig() {
  const file = path.join(process.cwd(), 'config', 'bot.yaml')
  const raw = fs.readFileSync(file, 'utf8')
  // Suporte simples a ${ENV}
  const templated = raw.replace(/\$\{([^}]+)\}/g, (_, key) => process.env[key] ?? '')
  const cfg = YAML.parse(templated)
  return cfg || {}
}

async function loadUserBotConfig(userId?: string) {
  if (!userId) {
    return loadGlobalBotConfig()
  }
  
  try {
    return await getUserBotConfig(userId)
  } catch (error) {
    console.warn(`Failed to load user config for ${userId}, using global:`, error)
    return loadGlobalBotConfig()
  }
}

function buildSystemPrompt(cfg: any) {
  const name = cfg?.profile?.name || process.env.BOT_NAME || 'Atendente Sant√™'
  const business = cfg?.profile?.business || process.env.BUSINESS_NAME || 'Sant√™ Moda'
  const tone = cfg?.profile?.tone || 'Vendedor consultivo e simp√°tico.'
  const products = (cfg?.profile?.products || []).join(', ')
  const rules = (cfg?.rules || []).map((r: string) => `- ${r}`).join('\n')
  const memory = (cfg?.memory || []).map((m: string) => `- ${m}`).join('\n')

  return `Voc√™ √© ${name}, atendente do neg√≥cio ${business}.
Tom: ${tone}
Produtos/Servi√ßos: ${products || 'moda praia e casual da Sant√™'}.
Regras de atendimento:
${rules || '- Seja claro, objetivo e prestativo.'}
Mem√≥ria do neg√≥cio:
${memory || '- Sem mem√≥ria adicional.'}

Objetivo: ajudar o cliente a escolher produtos de moda. Se necess√°rio, pe√ßa tamanho/numera√ß√£o e prefer√™ncias. Sempre finalize com um pr√≥ximo passo claro (CTA leve).`
}

// Simple knowledge selection for user-specific content
function selectKnowledgeSections(query: string, userKnowledge: Array<{ heading: string; content: string; raw: string; index: number }>): Array<{ heading: string; content: string; raw: string; index: number; score?: number }> {
  if (!query || userKnowledge.length === 0) {
    return []
  }
  
  const queryWords = query.toLowerCase().split(/\s+/).filter(w => w.length > 2)
  
  const scored = userKnowledge.map(section => {
    const contentLower = (section.heading + ' ' + section.content).toLowerCase()
    const score = queryWords.reduce((acc, word) => {
      const matches = (contentLower.match(new RegExp(word, 'g')) || []).length
      return acc + matches
    }, 0)
    
    return { ...section, score }
  }).filter(section => section.score > 0)
  
  // Sort by score descending, take top 3
  return scored.sort((a, b) => (b.score || 0) - (a.score || 0)).slice(0, 3)
}

export async function reply(input: ReplyInput): Promise<string> {
  const cfg = await loadUserBotConfig(input.userId)
  const systemBase = buildSystemPrompt(cfg)
  
  // Selecionar se√ß√µes relevantes da base de conhecimento do usu√°rio
  let sections: any[] = []
  if (input.userId) {
    try {
      const userKnowledge = await getUserKnowledgeForAI(input.userId)
      sections = selectKnowledgeSections(input.text || '', userKnowledge)
    } catch (error) {
      console.warn(`Failed to load user knowledge for ${input.userId}, using global:`, error)
      sections = selectSections(input.text || '')
    }
  } else {
    sections = selectSections(input.text || '')
  }
  
  // üõ°Ô∏è CAMADA 1: CONTROLE DE CONTEXTO M√çNIMO
  if (sections.length === 0 || sections.every(s => (s.score || 0) === 0)) {
    logger.warn({ text: input.text, userId: input.userId }, '[ai][no_context]')
    return generateFallbackResponse(input.text, cfg)
  }
  
  const contextBlock = sections.map(s => `(Se√ß√£o: ${s.heading})\n${s.content.trim()}`).join('\n\n')
  
  // üõ°Ô∏è CAMADA 2: PROMPT ULTRA-RESTRITIVO
  const system = `${systemBase}

REGRAS CR√çTICAS DE RESPOSTA:
1. Voc√™ DEVE responder APENAS com informa√ß√µes presentes no contexto abaixo
2. Se a informa√ß√£o n√£o estiver no contexto, responda: "Preciso confirmar essa informa√ß√£o com nossa equipe. Posso te ajudar com algo que temos dispon√≠vel?"
3. NUNCA invente: pre√ßos, produtos, pol√≠ticas, hor√°rios, endere√ßos ou qualquer informa√ß√£o
4. NUNCA use conhecimento geral da web ou treinamento anterior
5. Mantenha respostas focadas no neg√≥cio e objetivas
6. Se cliente perguntar algo fora do contexto, redirecione para op√ß√µes dispon√≠veis

CONTEXTO AUTORIZADO (√öNICA FONTE DE VERDADE):
${contextBlock}

Responda como ${cfg?.profile?.name || 'Atendente'} baseado EXCLUSIVAMENTE no contexto acima.`
  
  const apiKey = process.env.OPENAI_API_KEY
  const model = process.env.OPENAI_MODEL || 'gpt-4o-mini'

  // Fallback sem OpenAI
  if (!apiKey) {
    logger.warn('OPENAI_API_KEY n√£o definido ‚Äî usando fallback controlado.')
    return generateContextualFallback(input.text, sections, cfg)
  }

  try {
    const body = {
      model,
      messages: [
        { role: 'system', content: system },
        { role: 'user', content: input.text }
      ],
      temperature: 0.3, // üõ°Ô∏è CAMADA 3: BAIXA CRIATIVIDADE
      max_tokens: 300,  // Respostas concisas
      top_p: 0.8       // Menos variabilidade
    }

    const res = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(body)
    })

    if (!res.ok) {
      const err = await res.text()
      logger.error({ err }, 'Erro OpenAI')
      return generateContextualFallback(input.text, sections, cfg)
    }
    
    const data = await res.json() as any
    let aiResponse = data.choices?.[0]?.message?.content?.trim()
    
    // üõ°Ô∏è CAMADA 4: VALIDA√á√ÉO P√ìS-RESPOSTA
    if (!aiResponse) {
      return generateContextualFallback(input.text, sections, cfg)
    }
    
    // Detectar respostas muito gen√©ricas ou fora do contexto
    if (isGenericResponse(aiResponse) || !hasContextualRelevance(aiResponse, sections)) {
      logger.warn({ response: aiResponse.slice(0, 50) }, '[ai][generic_detected]')
      return generateContextualFallback(input.text, sections, cfg)
    }
    
    return aiResponse
    
  } catch (error: any) {
    logger.error({ error: error.message }, 'Erro chamada OpenAI')
    return generateContextualFallback(input.text, sections, cfg)
  }
}

// üéØ FALLBACK QUANDO SEM CONTEXTO
function generateFallbackResponse(text: string, cfg: any): string {
  const name = cfg?.profile?.name || 'Atendente'
  const business = cfg?.profile?.business || 'nossa loja'
  
  const responses = [
    `Oi! Sou ${name} da ${business}. No que posso te ajudar hoje?`,
    `Ol√°! Seja bem-vindo √† ${business}. Em que posso ajudar?`,
    `Oi! Como posso ajudar voc√™ hoje na ${business}?`
  ]
  
  return responses[Math.floor(Math.random() * responses.length)]
}

// üéØ FALLBACK CONTEXTUAL (com base nas se√ß√µes encontradas)
function generateContextualFallback(text: string, sections: any[], cfg: any): string {
  const name = cfg?.profile?.name || 'Atendente'
  
  if (sections.length > 0) {
    const topSection = sections[0]
    return `Oi! Sou ${name}. Vi que voc√™ est√° interessado em algo relacionado a ${topSection.heading.toLowerCase()}. Posso te ajudar com mais detalhes sobre isso!`
  }
  
  return generateFallbackResponse(text, cfg)
}

// üîç DETECTAR RESPOSTAS GEN√âRICAS
function isGenericResponse(response: string): boolean {
  const genericPhrases = [
    'posso ajudar com isso',
    'vou verificar para voc√™',
    'deixe-me consultar',
    'vou checar nossa disponibilidade',
    'preciso verificar com',
    'como posso ajudar',
    'em que posso ajudar'
  ]
  
  const lowerResponse = response.toLowerCase()
  return genericPhrases.some(phrase => lowerResponse.includes(phrase)) && response.length < 100
}

// üîç VERIFICAR RELEV√ÇNCIA CONTEXTUAL
function hasContextualRelevance(response: string, sections: any[]): boolean {
  if (sections.length === 0) return false
  
  const responseWords = response.toLowerCase().split(/\s+/)
  const contextWords = sections
    .map(s => (s.heading + ' ' + s.content).toLowerCase())
    .join(' ')
    .split(/\s+/)
  
  const relevantWords = responseWords.filter(word => 
    word.length > 3 && contextWords.includes(word)
  )
  
  // Pelo menos 10% das palavras devem vir do contexto
  return relevantWords.length >= Math.max(1, responseWords.length * 0.1)
}